{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepFake_From_Single_Image.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkeldenich/DeepFake_From_Single_Image/blob/main/DeepFake_From_Single_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES_gdmTtB5SQ"
      },
      "source": [
        "<img src=\"https://imgur.com/QyYZJVD.gif\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mtt3tnAbSdL",
        "cellView": "form"
      },
      "source": [
        "#@title #**Deep Fake Video/Gif** à partir d'**une seule image**, plus d'informations [ici](https://inside-machinelearning.com/) !\n",
        "\n",
        "#@markdown Les étapes:\n",
        "\n",
        "#@markdown - **Importez** votre image\n",
        "#@markdown - Entrez le **nom de l'image** ici:\n",
        "Nom_Fichier_Image = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - **Importez** la vidéo à reproduire\n",
        "#@markdown - Entrez le **nom de la vidéo** ici:\n",
        "Nom_Fichier_Video = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Puis **exécutez le code** en appuyant sur les **touches** \"Shift + Entrer\" ! :)\n",
        "\n",
        "#Clone repository\n",
        "\n",
        "!git clone https://github.com/AliaksandrSiarohin/first-order-model &> /dev/null\n",
        "\n",
        "!git clone https://github.com/tkeldenich/DeepFake_From_Single_Image.git &> /dev/null",
        "\n",
        "%cd /content/first-order-model\n",
        "\n",
        "#Load driving video and source image\n",
        "\n",
        "import imageio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from skimage.transform import resize\n",
        "from IPython.display import HTML\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "source_image = imageio.imread('/content/'+Nom_Fichier_Image)\n",
        "reader = imageio.get_reader('/content/'+Nom_Fichier_Video)\n",
        "\n",
        "\n",
        "#Resize image and video to 256x256\n",
        "\n",
        "source_image = resize(source_image, (256, 256))[..., :3]\n",
        "\n",
        "fps = reader.get_meta_data()['fps']\n",
        "driving_video = []\n",
        "try:\n",
        "    for im in reader:\n",
        "        driving_video.append(im)\n",
        "except RuntimeError:\n",
        "    pass\n",
        "reader.close()\n",
        "\n",
        "driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
        "\n",
        "def display(source, driving, generated=None):\n",
        "    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n",
        "\n",
        "    ims = []\n",
        "    for i in range(len(driving)):\n",
        "        cols = [source]\n",
        "        cols.append(driving[i])\n",
        "        if generated is not None:\n",
        "            cols.append(generated[i])\n",
        "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
        "        plt.axis('off')\n",
        "        ims.append([im])\n",
        "\n",
        "    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
        "    plt.close()\n",
        "    return ani\n",
        "    \n",
        "\n",
        "HTML(display(source_image, driving_video).to_html5_video())\n",
        "\n",
        "#Create a model and load checkpoints\n",
        "#import from googledrive\n",
        "!wget -q --show-progress --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1coUCdyRXDbpWnEkA99NLNY60mb9dQ_n3' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1coUCdyRXDbpWnEkA99NLNY60mb9dQ_n3\" -O /content/vox-adv-cpk.pth.tar && rm -rf /tmp/cookies.txt &> /dev/null\n",
        "\n",
        "from demo import load_checkpoints\n",
        "generator, kp_detector = load_checkpoints(config_path='/content/first-order-model/config/vox-256.yaml',\n",
        "                                          checkpoint_path='/content/vox-adv-cpk.pth.tar')\n",
        "\n",
        "#Perform image animation\n",
        "\n",
        "from demo import make_animation\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True)\n",
        "\n",
        "#save resulting video\n",
        "imageio.mimsave('../generated.mp4', [img_as_ubyte(frame) for frame in predictions], fps=fps)\n",
        "#video can be downloaded from /content folder\n",
        "\n",
        "#HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
        "\n",
        "#In the cell above we use relative keypoint displacement to animate the objects. We can use absolute coordinates instead,\n",
        "#but in this way all the object proporions will be inherited from the driving video.\n",
        "#For example Putin haircut will be extended to match Trump haircut.\n",
        "\n",
        "predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=False, adapt_movement_scale=True)\n",
        "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
        "\n",
        "#Running on your data\n",
        "\n",
        "source_image = imageio.imread('/content/'+Nom_Fichier_Image)\n",
        "driving_video = imageio.mimread('/content/'+Nom_Fichier_Video, memtest=False)\n",
        "\n",
        "\n",
        "#Resize image and video to 256x256\n",
        "\n",
        "source_image = resize(source_image, (256, 256))[..., :3]\n",
        "driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
        " \n",
        "predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True,\n",
        "                             adapt_movement_scale=True)\n",
        "\n",
        "imageio.mimsave('generated.mp4', [img_as_ubyte(frame) for frame in predictions], fps=fps)\n",
        "\n",
        "HTML(display(source_image, driving_video, predictions).to_html5_video())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
